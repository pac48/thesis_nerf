{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef54103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from laplacian_py import laplacian_solver\n",
    "\n",
    "res = 30\n",
    "max_val = 40\n",
    "cost_scale = .02\n",
    "\n",
    "values = .99*max_val*torch.ones((res, res, res),dtype=torch.float32, device='cuda')\n",
    "cost = cost_scale*torch.ones((res,res, res),dtype=torch.float32, device='cuda')\n",
    "boundary_conditions = torch.zeros((res,res, res),dtype=torch.float32, device='cuda')\n",
    "boundary_types = torch.zeros((res,res, res),dtype=torch.float32, device='cuda')\n",
    "# goal\n",
    "goal_ind1 = int(res*15/30)\n",
    "goal_ind2 = int(res*15/30)\n",
    "goal_ind3 = int(res*15/30)\n",
    "boundary_conditions[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "boundary_types[goal_ind1, goal_ind2, goal_ind3] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d61387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-931,  -31,  869, -901,   -1,  899, -871,   29,  929, -930,  -30,  870,\n",
      "        -900,  900, -870,   30,  930, -929,  -29,  871, -899,    1,  901, -869,\n",
      "          31,  931], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([30, 30, 30])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from laplacian_py.network import LaplaceNet, compute_loss, calculate_gradient\n",
    "    \n",
    "network = LaplaceNet((res, res, res), max_val, 1*cost_scale, 0)\n",
    "network.cuda(device='cuda')\n",
    "V_in = values.clone()\n",
    "\n",
    "print(network.indexes)\n",
    "print(network.C.shape)\n",
    "print(network.num_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009c0ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(242.8103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(399.2968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(329.2004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(283.7846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(270.7912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(259.1895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(247.6995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(236.5297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(225.7844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(215.5126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(205.7321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(196.4430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(187.6360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(179.2956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(171.4020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(163.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(156.8708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(150.1900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(143.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(137.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(132.2459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(126.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(121.8374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(117.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(112.5101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(108.2100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(104.1365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(100.2776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(96.6177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(93.1439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(89.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(86.7206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(83.7530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(80.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(78.2549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(75.7067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(73.2804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(70.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(68.7748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(66.6837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(64.6940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(62.8003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(60.9973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(59.2792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(57.6423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(56.0828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(54.5963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(53.1787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(51.8248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(50.5315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(49.2975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(48.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(46.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(45.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(44.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(43.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(42.9690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(42.0733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(41.2180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(40.4003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(39.6196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(38.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(38.1579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(37.4756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(36.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(36.2030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(35.6097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(35.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(34.5038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.9890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.4978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(33.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.5782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.1492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(31.7396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(31.3496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.9783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.2892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.9699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.6652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.3737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.0954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.5805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.3424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(28.1170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.7008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.5098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.3288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.1562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.6900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.5514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.4233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.3022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.1898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.0843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.9858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.7294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.6541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.5849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.5191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.4612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.4058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.3540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.3066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.0865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.1811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.2919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.3212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.3493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.3827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.4176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.4436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.4768, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.5150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.5520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.5920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.6236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.6642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.7051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.7466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.7858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.9572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.9974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.0882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.1266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.1689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.2134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.2592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.3052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.3501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.3908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.4360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.4834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.5297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.5692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.6094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.6525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.6993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.7415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.7791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.9872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.0238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.1045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.1465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.1858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.2245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.2650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.3062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.3447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.3850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.4248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.4642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.5003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.5381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.5755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.6095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.6458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.6811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.7170, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2 # norm\n",
    "# lr = 1e-4 # abs\n",
    "momentum = 0.99\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "XYZ_train = [np.linspace(-1, 1, int(res), dtype=np.float32) for _ in range(3)]\n",
    "X_train, Y_train, Z_train = np.meshgrid(*XYZ_train)\n",
    "out = np.stack([X_train, Y_train, Z_train], axis=3)\n",
    "grid_train = torch.tensor(out, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "grid_train = grid_train.unsqueeze(axis=0)\n",
    "\n",
    "\n",
    "# target = torch.tensor(5*X_train+5*Y_train +5*Z_train + 15,dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(15*Z_train + 15,dtype=torch.float32, device='cuda')\n",
    "target = torch.tensor(30*np.sqrt(X_train**2+Y_train**2),dtype=torch.float32, device='cuda')\n",
    "\n",
    "# target = torch.tensor(20*X + 0,dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(12*(X**2+Y**2+Z**2) + 0,dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(15 + 0*X,dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(10*Y + 10*(1-X), dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(10*(1-Y) + 10*X, dtype=torch.float32, device='cuda')\n",
    "\n",
    "# target = target.unsqueeze(axis=0)\n",
    "network.reset()\n",
    "for it in range(0, 2000):\n",
    "    optimizer.zero_grad()\n",
    "    pred, C, _ = network(grid_train, boundary_types, boundary_conditions)\n",
    "    loss_train = 1*compute_loss(pred=pred, target=target, C=C, cost_scale=cost_scale)\n",
    "    if it % 10 == 0:\n",
    "        print(loss_train)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38437740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(network.V)\n",
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356aba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_types_2 = boundary_types.clone()\n",
    "boundary_conditions_2 = boundary_conditions.clone()\n",
    "\n",
    "\n",
    "# obj1_ind1 = int(res*18/30)\n",
    "# obj1_ind2 = int(res*2/3)\n",
    "# obj1_ind3 = int(res*0)\n",
    "# obj1_ind4 = int(res*2/3)\n",
    "# boundary_conditions_2[obj1_ind1:obj1_ind2, obj1_ind3:obj1_ind4] = max_val*10\n",
    "# boundary_types_2[obj1_ind1:obj1_ind2, obj1_ind3:obj1_ind4] = 1.0\n",
    "\n",
    "# obj2_ind1 = int(res*3/12)\n",
    "# obj2_ind2 = int(res*4/12)\n",
    "# obj2_ind3 = int(res*1/3)\n",
    "# obj2_ind4 = int(res*28/30)\n",
    "# boundary_conditions_2[obj2_ind1:obj2_ind2, obj2_ind3:obj2_ind4] = max_val*10\n",
    "# boundary_types_2[obj2_ind1:obj2_ind2, obj2_ind3:obj2_ind4] = 1.0\n",
    "\n",
    "\n",
    "# obj1_ind1 = int(res*1/3)\n",
    "# obj1_ind2 = int(res*2/3)\n",
    "# obj1_ind3 = int(res*1/3)\n",
    "# obj1_ind4 = int(res*2/3)\n",
    "# boundary_conditions_2[obj1_ind1:obj1_ind2, obj1_ind3:obj1_ind4] = max_val*10\n",
    "# boundary_types_2[obj1_ind1:obj1_ind2, obj1_ind3:obj1_ind4] = 1.0\n",
    "\n",
    "\n",
    "# tmp_inds = boundary_types_2 > 0\n",
    "# tmp_inds = tmp_inds*(torch.rand(tmp_inds.shape,dtype=torch.float32, device='cuda')>.03)\n",
    "# boundary_types_2[tmp_inds] = 0\n",
    "# boundary_conditions_2[tmp_inds] = 0\n",
    "# boundary_conditions_2[goal_ind1, goal_ind2] = 0.0\n",
    "# boundary_types_2[goal_ind1, goal_ind2] = 1.0\n",
    "\n",
    "# network.reset()\n",
    "for i in range(1000):\n",
    "    pred, C_pos, J2 = network(grid_train, boundary_types_2, boundary_conditions_2)\n",
    "    V_in = pred.detach()\n",
    " \n",
    "pred[pred>max_val] = max_val\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74997e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "z = pred.cpu().detach().numpy()[1:-1, 1:-1, 1:-1]\n",
    "X = np.linspace(-15, 15, z.shape[0])\n",
    "Y = np.linspace(-15, 15, z.shape[1])\n",
    "Z = np.linspace(-15, 15, z.shape[2])\n",
    "X, Y, Z = np.meshgrid(X, Y, Z)\n",
    "\n",
    "\n",
    "# # ax = plt.figure().add_subplot(projection='3d')\n",
    "# ax = plt.figure(figsize=(20, 20)).add_subplot(projection='3d')\n",
    "\n",
    "# Up = -np.diff(z[1:-2, 2:-2, 2:-2], axis=0)\n",
    "# Vp = -np.diff(z[2:-2, 1:-2, 2:-2], axis=1)\n",
    "# Wp = -np.diff(z[2:-2, 2:-2, 1:-2], axis=2)\n",
    "\n",
    "# ax.quiver(X[2:-2, 2:-2, 2:-2], Y[2:-2,2:-2,2:-2], Z[2:-2,2:-2,2:-2], Vp, Up, Wp, length=0.5, normalize=True)\n",
    "\n",
    "# ax.view_init(30, 30, 0)\n",
    "# # f = plt.figure(figsize=(20, 20))\n",
    "# plt.show()\n",
    "# plt.pause(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6955d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "dt = 0.01\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "\n",
    "for x_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "    for y_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "        for z_val in [-.95, 0.0, .95]:\n",
    "            cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "            traj = np.zeros((1000, 3))\n",
    "            for i in range(traj.shape[0]):\n",
    "                query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "                query.unsqueeze(axis=0)\n",
    "                J1, J2 = calculate_gradient(grid_pred, query)\n",
    "                J2 = J2.cpu().detach().numpy()\n",
    "                J2 = J2/(np.linalg.norm(J2) + .00000000001)\n",
    "                cur += -J2*dt\n",
    "#                 print(J2)\n",
    "#                 print(cur)\n",
    "                traj[i, :] = cur.squeeze()\n",
    "\n",
    "            ax.plot(traj[:,0], traj[:,1], traj[:,2])\n",
    "    \n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "plt.pause(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d928ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 0.01\n",
    "# ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "# for x_val in [-.99, -.5, 0, .5 ,.99]:\n",
    "#     for y_val in [-.99, -.5, 0, .5 ,.99]:\n",
    "#         for z_val in [.95]:\n",
    "#             cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "#             traj = np.zeros((1000, 3))\n",
    "#             for i in range(traj.shape[0]):\n",
    "#                 query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "#                 query.unsqueeze(axis=0)\n",
    "#                 _, _, J2 = network(query, boundary_types_2, boundary_conditions_2)\n",
    "#                 J2 = J2.cpu().detach().numpy()\n",
    "#                 J2 = J2/(np.linalg.norm(J2) + .00000000001)\n",
    "#                 cur += -J2*dt\n",
    "#                 traj[i, :] = cur     \n",
    "\n",
    "#             ax.plot(traj[:,0], traj[:,1], traj[:,2])\n",
    "\n",
    "# ax.set_xlabel('X Label')\n",
    "# ax.set_ylabel('Y Label')\n",
    "# ax.set_zlabel('Z Label')\n",
    "# plt.show()\n",
    "\n",
    "# plt.pause(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac02a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38., device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.V[2,2,2]\n",
    "# boundary_types_2[2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "                               \n",
    "val = pred[1:-1, 1:-1, 1:-1].cpu().detach().numpy()\n",
    "\n",
    "skip = 1\n",
    "color = val[0:-1:skip, 0:-1:skip, 0:-1:skip]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(X[0:-1:skip,0:-1:skip,0:-1:skip], Y[0:-1:skip,0:-1:skip,0:-1:skip], Z[0:-1:skip,0:-1:skip,0:-1:skip],\n",
    "          c=color)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "plt.pause(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5736f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:-1:skip,0:-1:skip,0:-1:skip].shape\n",
    "color.shape\n",
    "X.shape\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d84ad18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-931,  869, -871,  929, -929,  871, -869,  931], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "res_in = (res, res, res)\n",
    "num_dims = len(res_in)\n",
    "dims_linear = torch.zeros(num_dims, dtype=torch.int32)\n",
    "base = 1\n",
    "for ind, d in enumerate(res_in):\n",
    "    dims_linear[ind] = base\n",
    "    base = base * d\n",
    "\n",
    "indexes = torch.tensor([torch.sum(torch.tensor(v, dtype=torch.int32) * dims_linear) for v in\n",
    "                     list(itertools.product([-1, 1], repeat=num_dims)) if\n",
    "                     not all(vi == 0 for vi in v)], dtype=torch.int32, device='cuda')\n",
    "\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f550ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83e938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90dd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95916a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551271d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nerf",
   "language": "python",
   "name": "thesis_nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
