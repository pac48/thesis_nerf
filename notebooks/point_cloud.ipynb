{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef54103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from laplacian_py import laplacian_solver\n",
    "\n",
    "resx = 80\n",
    "resy = 30\n",
    "resz = 50\n",
    "\n",
    "resx = 64\n",
    "resy = 64\n",
    "resz = 64\n",
    "\n",
    "max_val = 100\n",
    "cost_scale = .1\n",
    "\n",
    "values = .99*max_val*torch.ones((resx, resy, resz),dtype=torch.float32, device='cuda')\n",
    "cost = cost_scale*torch.ones((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_conditions = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_types = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "# goal\n",
    "goal_ind1 = int(resx*15/30)\n",
    "goal_ind2 = int(resy*15/30)\n",
    "goal_ind3 = int(resz*15/30)\n",
    "boundary_conditions[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "boundary_types[goal_ind1, goal_ind2, goal_ind3] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7f189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ce609e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m18:58:40 \u001b[0;32mSUCCESS  \u001b[0mInitialized CUDA 12.0. Active GPU is #0: NVIDIA GeForce RTX 4090 [89]\u001b[K\u001b[0m\n",
      "18:58:40 \u001b[0;36mINFO     \u001b[0mLoading network snapshot from: ../nerf/table.ingp\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.41 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 B.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.12 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 4 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 2 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 64 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;36mINFO     \u001b[0mGridEncoding:  Nmin=16 b=2 F=4 T=2^22 L=8\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 0: resolution=16 params_in_level=4096\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 1: resolution=32 params_in_level=32768\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 2: resolution=64 params_in_level=262144\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 3: resolution=128 params_in_level=2097152\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 4: resolution=256 params_in_level=4194304\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 5: resolution=512 params_in_level=4194304\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 6: resolution=1024 params_in_level=4194304\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 7: resolution=2048 params_in_level=4194304\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;36mINFO     \u001b[0mDensity model: 3--[HashGrid]-->32--[FullyFusedMLP(neurons=128,layers=4)]-->1\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;36mINFO     \u001b[0mColor model:   3--[Composite]-->16+16--[FullyFusedMLP(neurons=64,layers=4)]-->3\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 2048 params and resetting training.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 24 KB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;36mINFO     \u001b[0m  total_encoding_params=76693504 total_network_params=29696\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 76723200 params and resetting training.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 585 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 0 params and resetting training.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 7 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 4 MB.\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 0 B to 8 MB\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 8 MB to 24 MB\u001b[K\u001b[0m\n",
      "18:58:42 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 24 MB to 40 MB\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts.point_cloud_utils import send_point_cloud\n",
    "from pyngp.common import *\n",
    "from tqdm import tqdm\n",
    "import pyngp.pyngp as ngp\n",
    "testbed = ngp.Testbed()\n",
    "testbed.load_snapshot('../nerf/table.ingp')\n",
    "\n",
    "box_diff = testbed.aabb.max - testbed.aabb.min\n",
    "min_dim = -box_diff / 2\n",
    "max_dim = box_diff / 2\n",
    "\n",
    "x_segments = np.linspace(.2, .8, resx)\n",
    "y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "z_segments = np.linspace(.35, .65, resz)\n",
    "x, y, z = np.meshgrid(x_segments, y_segments, z_segments, indexing='ij')\n",
    "points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)\n",
    "points = points[0:256 * (points.shape[0] // 256), :]\n",
    "\n",
    "dirs = np.zeros(points.shape)\n",
    "dirs[:, 0] = 1\n",
    "dirs[:, 1] = .5\n",
    "dirs[:, 2] = .5\n",
    "\n",
    "dt = np.zeros((points.shape[0], 1))\n",
    "coords = np.hstack((points, dt, dirs))\n",
    "nerf_values = testbed.sample_nerf(list(coords.flatten()))\n",
    "nerf_values = np.reshape(nerf_values, (coords.shape[0], -1))\n",
    "\n",
    "points = np.vstack((points[:, 0], points[:, 2], 1 - points[:, 1])).T\n",
    "points = points * (max_dim - min_dim) + min_dim\n",
    "points = 2 * points\n",
    "\n",
    "send_point_cloud(np.hstack((points, nerf_values)), has_alpha=False, wait_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3297741b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4369.066666666667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerf_values.shape[0]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d61387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from laplacian_py.network import LaplaceNet, compute_loss, calculate_gradient\n",
    "    \n",
    "network = LaplaceNet((resx, resy, resz), max_val, 1*cost_scale, 2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "network = network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009c0ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/CLionProjects/thesis_nerf/nerf_ws/install/laplacian_py/lib/python3.10/site-packages/laplacian_py/network.py:29: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  extra_cost = F.conv3d(objects_bounds.unsqueeze(dim=0), weight, bias=None, stride=1, padding='same',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6486.8105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(760.6436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(688.4364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(728.6790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(773.2325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(780.5591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(777.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(774.6123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(771.1303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(767.4056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(763.4558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(759.3008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(754.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(750.4391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(745.7643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(740.9490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(736.0565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(731.2019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.4784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.9524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(717.6682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(713.6438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(709.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(706.4108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(703.2090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(700.2653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(697.5725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(695.1146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(692.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(690.8333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(688.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(687.2896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(685.7564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(684.3619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(683.0903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(681.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(680.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(679.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(679.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(678.1903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(677.4374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(676.7423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(676.1003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(675.5066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(674.9557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(674.4454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(673.9711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(673.5289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(673.1164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(672.7310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(672.3697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(672.0316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(671.7141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(671.4155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(671.1345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(670.8690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(670.6185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(670.3827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(670.1592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.9464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.7444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.5529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.3708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.1977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(669.0326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.7224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.5773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.4396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.3076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.1807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(668.0588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.8281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.7188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.6138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.5127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.4156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.3226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.2330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.1458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(667.0604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.9771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.8193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.7443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.6717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.6013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.5334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.4682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.4045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.3417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.2797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.2190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.1608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.1044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(666.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(665.9947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(665.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(665.8897, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2 # norm\n",
    "# lr = 1e-4 # abs\n",
    "momentum = 0.99\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "XYZ_train = [np.linspace(-1, 1, res, dtype=np.float32) for res in [resx, resy, resz]]\n",
    "X_train, Y_train, Z_train = np.meshgrid(*XYZ_train)\n",
    "out = np.stack([X_train, Y_train, Z_train], axis=3)\n",
    "grid_train = torch.tensor(out, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "grid_train = grid_train.unsqueeze(axis=0)\n",
    "\n",
    "# target = torch.tensor(10+20*np.sqrt(X_train**2+Y_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(10+20*np.sqrt(X_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "target = torch.tensor(21+20*Y_train,dtype=torch.float32, device='cuda')\n",
    "\n",
    "    \n",
    "network.reset()\n",
    "for it in range(0, 1000):\n",
    "    optimizer.zero_grad()\n",
    "    pred, C, _ = network(grid_train, boundary_types, boundary_conditions)\n",
    "    loss_train = 1*compute_loss(pred=pred, target=target, C=C, cost_scale=cost_scale)\n",
    "    if it % 10 == 0:\n",
    "        print(loss_train)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "# network = torch.load('network_3d.pt')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38437740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "                               \n",
    "val = pred.cpu().detach().numpy()[1:-1,1:-1,1:-1]\n",
    "\n",
    "skip = 2\n",
    "color = val[0:-1:skip, 0:-1:skip, 0:-1:skip]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(X_train[1:-1:skip,1:-1:skip,1:-1:skip], Y_train[1:-1:skip,1:-1:skip,1:-1:skip], Z_train[1:-1:skip,1:-1:skip,1:-1:skip],\n",
    "          c=color)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "plt.pause(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356aba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_types_2 = boundary_types.clone()\n",
    "boundary_conditions_2 = boundary_conditions.clone()\n",
    "\n",
    "\n",
    " \n",
    "obj_inds = nerf_values[:,3] > 100/255\n",
    "obj_inds = np.reshape(obj_inds, (resx,resy,resz))\n",
    "boundary_conditions_2[obj_inds] = max_val*10\n",
    "boundary_types_2[obj_inds] = 1.0\n",
    "\n",
    "\n",
    "network.reset()\n",
    "for i in range(1000):\n",
    "    pred, C_pos, J2 = network(grid_train, boundary_types_2, boundary_conditions_2)\n",
    "    V_in = pred.detach()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833b2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from visualization_msgs.msg import MarkerArray, Marker\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "node = Node('visualizer_node')\n",
    "pub = node.create_publisher(MarkerArray, 'visualization_lines', 10)\n",
    "    \n",
    "msg = MarkerArray()\n",
    "\n",
    "dt = 0.005\n",
    "marker_id = 0\n",
    "grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "\n",
    "x_min = points[0,0]\n",
    "y_min = points[0,1]\n",
    "z_min = points[0,2]\n",
    "x_max = points[-1,0]\n",
    "y_max = points[-1,1]\n",
    "z_max = points[-1,2]\n",
    "\n",
    "# x_segments = np.linspace(.2, .8, resx)\n",
    "# y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "# z_segments = np.linspace(.35, .65, resz)\n",
    "\n",
    "\n",
    "for z_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "    for y_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "        for x_val in [-.95, 0.0, .95]:\n",
    "            cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "            traj = np.zeros((1000, 3))\n",
    "            for i in range(traj.shape[0]):\n",
    "                query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "                query.unsqueeze(axis=0)\n",
    "                J1, J2 = calculate_gradient(grid_pred, query)\n",
    "                J2 = J2.cpu().detach().numpy()\n",
    "                J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "                cur += -J2*dt\n",
    "                traj[i, :] = cur.squeeze()\n",
    "    \n",
    "            marker = Marker()\n",
    "            marker.header.frame_id = \"unity\";\n",
    "            marker.id = marker_id;\n",
    "            marker_id += 1\n",
    "            marker.type = marker.LINE_STRIP;\n",
    "            marker.action = marker.ADD;\n",
    "\n",
    "            for ind in range(traj.shape[0]):\n",
    "                position = Point()\n",
    "                position.x = .5*(traj[ind, 2]+1.0)*(x_max-x_min) + x_min\n",
    "                position.y = .5*(traj[ind, 1]+1.0)*(y_max-y_min) + y_min\n",
    "                position.z = .5*(traj[ind, 0]+1.0)*(z_max-z_min) + z_min\n",
    "                marker.points.append(position)\n",
    "\n",
    "            marker.scale.x = .001;\n",
    "            marker.scale.y = 0.0;\n",
    "            marker.scale.z = 0.0;\n",
    "            marker.color.a = 1.0; \n",
    "            marker.color.r = 0.0;\n",
    "            marker.color.g = 0.0;\n",
    "            marker.color.b = 1.0;\n",
    "\n",
    "            msg.markers.append(marker)\n",
    "\n",
    "\n",
    "pub.publish(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e49947f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pub.publish(msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6955d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 0.01\n",
    "# ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "# grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "\n",
    "# for x_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "#     for y_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "#         for z_val in [-.95, 0.0, .95]:\n",
    "#             cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "#             traj = np.zeros((1000, 3))\n",
    "#             for i in range(traj.shape[0]):\n",
    "#                 query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "#                 query.unsqueeze(axis=0)\n",
    "#                 J1, J2 = calculate_gradient(grid_pred, query)\n",
    "#                 J2 = J2.cpu().detach().numpy()\n",
    "#                 J2 = J2/(np.linalg.norm(J2) + .1)\n",
    "#                 cur += -J2*dt\n",
    "# #                 print(J2)\n",
    "# #                 print(cur)\n",
    "#                 traj[i, :] = cur.squeeze()\n",
    "\n",
    "#             ax.plot(traj[:,0], traj[:,1], traj[:,2])\n",
    "    \n",
    "# obj_inds = (boundary_types_2 == 1).cpu().numpy()\n",
    "# ax.scatter(X_train[obj_inds], Z_train[obj_inds],  Y_train[obj_inds])    \n",
    "# ax.set_xlabel('X Label')\n",
    "# ax.set_ylabel('Y Label')\n",
    "# ax.set_zlabel('Z Label')\n",
    "# plt.show()\n",
    "# plt.pause(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0425fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(network, 'network_3d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c595be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8c70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e479fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nerf",
   "language": "python",
   "name": "thesis_nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
