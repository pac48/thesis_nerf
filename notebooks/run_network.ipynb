{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6de83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from laplacian_py import laplacian_solver\n",
    "\n",
    "resx = 80\n",
    "resy = 30\n",
    "resz = 50\n",
    "\n",
    "resx = 2*64//1\n",
    "resy = 2*64//1\n",
    "resz = 2*64//1\n",
    "\n",
    "max_val = 100/1\n",
    "cost_scale = .1\n",
    "\n",
    "values = .99*max_val*torch.ones((resx, resy, resz),dtype=torch.float32, device='cuda')\n",
    "cost = cost_scale*torch.ones((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_conditions = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_types = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "# goal\n",
    "goal_ind1 = int(resx*15/30)\n",
    "goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*27/30)\n",
    "goal_ind3 = int(resz*15/30)\n",
    "boundary_conditions[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "boundary_types[goal_ind1, goal_ind2, goal_ind3] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffe0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m17:13:34 \u001b[0;32mSUCCESS  \u001b[0mInitialized CUDA 12.0. Active GPU is #0: NVIDIA GeForce RTX 4090 [89]\u001b[K\u001b[0m\n",
      "17:13:34 \u001b[0;36mINFO     \u001b[0mLoading network snapshot from: ../nerf/scene.ingp\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.41 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 B.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.12 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 4 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 2 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 64 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;36mINFO     \u001b[0mGridEncoding:  Nmin=16 b=2 F=4 T=2^22 L=8\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 0: resolution=16 params_in_level=4096\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 1: resolution=32 params_in_level=32768\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 2: resolution=64 params_in_level=262144\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 3: resolution=128 params_in_level=2097152\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 4: resolution=256 params_in_level=4194304\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 5: resolution=512 params_in_level=4194304\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 6: resolution=1024 params_in_level=4194304\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 7: resolution=2048 params_in_level=4194304\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;36mINFO     \u001b[0mDensity model: 3--[HashGrid]-->32--[FullyFusedMLP(neurons=128,layers=4)]-->1\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;36mINFO     \u001b[0mColor model:   3--[Composite]-->16+16--[FullyFusedMLP(neurons=64,layers=4)]-->3\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 2048 params and resetting training.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 24 KB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;36mINFO     \u001b[0m  total_encoding_params=76693504 total_network_params=29696\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 76723200 params and resetting training.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 585 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 0 params and resetting training.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "17:13:36 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "17:13:38 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 56 MB.\u001b[K\u001b[0m\n",
      "17:13:38 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 32 MB.\u001b[K\u001b[0m\n",
      "17:13:38 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 0 B to 64 MB\u001b[K\u001b[0m\n",
      "17:13:38 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 64 MB to 192 MB\u001b[K\u001b[0m\n",
      "17:13:38 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 192 MB to 320 MB\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts.point_cloud_utils import send_point_cloud\n",
    "from pyngp.common import *\n",
    "from tqdm import tqdm\n",
    "import pyngp.pyngp as ngp\n",
    "testbed = ngp.Testbed()\n",
    "testbed.load_snapshot('../nerf/scene.ingp')\n",
    "\n",
    "box_diff = testbed.aabb.max - testbed.aabb.min\n",
    "min_dim = -box_diff / 2\n",
    "max_dim = box_diff / 2\n",
    "\n",
    "x_segments = np.linspace(.2, .8, resx)\n",
    "y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "z_segments = np.linspace(.35, .65, resz)\n",
    "x, y, z = np.meshgrid(x_segments, y_segments, z_segments, indexing='ij')\n",
    "points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)\n",
    "points = points[0:256 * (points.shape[0] // 256), :]\n",
    "\n",
    "dirs = np.zeros(points.shape)\n",
    "dirs[:, 0] = 1\n",
    "dirs[:, 1] = .5\n",
    "dirs[:, 2] = .5\n",
    "\n",
    "dt = np.zeros((points.shape[0], 1))\n",
    "coords = np.hstack((points, dt, dirs))\n",
    "nerf_values = testbed.sample_nerf(list(coords.flatten()))\n",
    "nerf_values = np.reshape(nerf_values, (coords.shape[0], -1))\n",
    "\n",
    "points = np.vstack((points[:, 0], points[:, 2], 1 - points[:, 1])).T\n",
    "points = points * (max_dim - min_dim) + min_dim\n",
    "points = 2 * points\n",
    "\n",
    "send_point_cloud(np.hstack((points, nerf_values)), has_alpha=False, wait_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7de0bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/CLionProjects/thesis_nerf/venv/lib/python3.10/site-packages/tinycudann-1.7-py3.10-linux-x86_64.egg/tinycudann/modules.py:53: UserWarning: tinycudann was built for lower compute capability (86) than the system's (89). Performance may be suboptimal.\n",
      "  warnings.warn(f\"tinycudann was built for lower compute capability ({cc}) than the system's ({system_compute_capability}). Performance may be suboptimal.\")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from laplacian_py.network import LaplaceNet, compute_loss, calculate_gradient, interpolate_prediction\n",
    "    \n",
    "network = LaplaceNet((resx, resy, resz), max_val, 1*cost_scale, 2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "network = network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07026087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/CLionProjects/thesis_nerf/nerf_ws/install/laplacian_py/lib/python3.10/site-packages/laplacian_py/network.py:32: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  extra_cost = F.conv3d(objects_bounds.unsqueeze(dim=0), weight, bias=None, stride=1, padding='same',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5145.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(451.2219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(239.4558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(205.1891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(236.7660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.2232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(250.8168, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4 # norm\n",
    "momentum = 0.8\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "XYZ_train = [np.linspace(-1, 1, res, dtype=np.float32) for res in [resx, resy, resz]]\n",
    "X_train, Y_train, Z_train = np.meshgrid(*XYZ_train)\n",
    "out = np.stack([X_train, Y_train, Z_train], axis=3)\n",
    "grid_train = torch.tensor(out, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "grid_train = grid_train.unsqueeze(axis=0)\n",
    "\n",
    "target = torch.tensor(10+20*np.sqrt(X_train**2+Y_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(10+20*np.sqrt(X_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(21 + 20*Y_train,dtype=torch.float32, device='cuda')\n",
    "\n",
    "    \n",
    "network.reset()\n",
    "for it in range(0, 200):\n",
    "    optimizer.zero_grad()\n",
    "    pred, C, _ = network(grid_train, boundary_types, boundary_conditions)\n",
    "    loss_train = 1*compute_loss(pred=pred, target=target, C=C, cost_scale=cost_scale)\n",
    "    if it % 10 == 0:\n",
    "        print(loss_train)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "# network = torch.load('network_3d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e802a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "boundary_types_2 = boundary_types.clone()\n",
    "boundary_conditions_2 = boundary_conditions.clone()\n",
    " \n",
    "obj_inds = nerf_values[:,3] > 100/255\n",
    "obj_inds = np.reshape(obj_inds, (resx, resy, resz))\n",
    "obj_inds = torch.tensor(obj_inds) # this should not be needed\n",
    "boundary_conditions_2[obj_inds] = max_val*10\n",
    "boundary_types_2[obj_inds] = 1.0\n",
    "\n",
    "# goal_ind1 = int(resx*15/30)\n",
    "# goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*15/30)\n",
    "# boundary_conditions_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "# boundary_types_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "\n",
    "# goal_ind1 = int(resx*15/30)\n",
    "# goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*27/30)\n",
    "# boundary_conditions_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "# boundary_types_2[goal_ind1, goal_ind2, goal_ind3] = 1.0\n",
    "\n",
    "# network.reset()\n",
    "for i in range(1000):\n",
    "    if i % 100 ==0:\n",
    "        print(i)\n",
    "    pred, C_pos, J2 = network(grid_train, boundary_types_2, boundary_conditions_2)\n",
    "    V_in = pred.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7de01307",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m                 query \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(cur, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m                 query\u001b[38;5;241m.\u001b[39munsqueeze(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m                 J1, J2 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m                 J2 \u001b[38;5;241m=\u001b[39m J2\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                 J2[abs(J2) != np.max(abs(J2))] = 0\u001b[39;00m\n",
      "File \u001b[0;32m~/CLionProjects/thesis_nerf/nerf_ws/install/laplacian_py/lib/python3.10/site-packages/laplacian_py/network.py:282\u001b[0m, in \u001b[0;36mcalculate_gradient\u001b[0;34m(grid_pred, query)\u001b[0m\n\u001b[1;32m    280\u001b[0m out \u001b[38;5;241m=\u001b[39m interpolate_prediction(grid_pred, query)\n\u001b[1;32m    281\u001b[0m dL_dout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(out\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m J1, J2 \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mout\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdL_dout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m J1, J2\n",
      "File \u001b[0;32m~/CLionProjects/thesis_nerf/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:300\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from visualization_msgs.msg import MarkerArray, Marker\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "node = Node('visualizer_node')\n",
    "pub = node.create_publisher(MarkerArray, 'visualization_lines', 10)\n",
    "    \n",
    "msg = MarkerArray()\n",
    "\n",
    "dt = 0.001\n",
    "marker_id = 0\n",
    "grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "\n",
    "x_min = points[0,0]\n",
    "y_min = points[0,1]\n",
    "z_min = points[0,2]\n",
    "x_max = points[-1,0]\n",
    "y_max = points[-1,1]\n",
    "z_max = points[-1,2]\n",
    "\n",
    "# x_segments = np.linspace(.2, .8, resx)\n",
    "# y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "# z_segments = np.linspace(.35, .65, resz)\n",
    "\n",
    "\n",
    "for z_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "    for y_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "        for x_val in [-.95, 0.0, .95]:\n",
    "            cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "            traj = np.zeros((2000, 3))\n",
    "            for i in range(traj.shape[0]):\n",
    "                query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "                query.unsqueeze(axis=0)\n",
    "                J1, J2 = calculate_gradient(grid_pred, query)\n",
    "                J2 = J2.cpu().detach().numpy()\n",
    "#                 J2[abs(J2) != np.max(abs(J2))] = 0\n",
    "                J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "                cur += -J2*dt\n",
    "                traj[i, :] = cur.squeeze()\n",
    "    \n",
    "            marker = Marker()\n",
    "            marker.header.frame_id = \"unity\";\n",
    "            marker.id = marker_id;\n",
    "            marker_id += 1\n",
    "            marker.type = marker.LINE_STRIP;\n",
    "            marker.action = marker.ADD;\n",
    "            \n",
    "            for ind in range(traj.shape[0]):\n",
    "                position = Point()\n",
    "                position.x = .5*(traj[ind, 2]+1.0)*(x_max-x_min) + x_min\n",
    "                position.y = .5*(traj[ind, 1]+1.0)*(y_max-y_min) + y_min\n",
    "                position.z = .5*(traj[ind, 0]+1.0)*(z_max-z_min) + z_min\n",
    "                marker.points.append(position)\n",
    "\n",
    "            marker.scale.x = .0025;\n",
    "            marker.scale.y = 0.0;\n",
    "            marker.scale.z = 0.0;\n",
    "            marker.color.a = 1.0; \n",
    "            marker.color.r = 0.0;\n",
    "            marker.color.g = 0.0;\n",
    "            marker.color.b = 1.0;\n",
    "\n",
    "            msg.markers.append(marker)\n",
    "\n",
    "\n",
    "pub.publish(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f5f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pub.publish(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44a29955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1698962681.103765201] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m goal[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(pos \u001b[38;5;241m-\u001b[39m goal) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m.01\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43mget_transform_ee\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright_gripper_l_finger_tip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     42\u001b[0m     xd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m6\u001b[39m,)\n\u001b[1;32m     43\u001b[0m     xd[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m(goal \u001b[38;5;241m-\u001b[39m pos)\n",
      "Cell \u001b[0;32mIn[115], line 25\u001b[0m, in \u001b[0;36mget_transform_ee\u001b[0;34m(base_frame, frame)\u001b[0m\n\u001b[1;32m     23\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m msg \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mrclpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m             msg \u001b[38;5;241m=\u001b[39m tf_buffer\u001b[38;5;241m.\u001b[39mlookup_transform(base_frame, frame,\n\u001b[1;32m     28\u001b[0m                                              rclpy\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mTime())\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py:202\u001b[0m, in \u001b[0;36mspin_once\u001b[0;34m(node, executor, timeout_sec)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     executor\u001b[38;5;241m.\u001b[39madd_node(node)\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     executor\u001b[38;5;241m.\u001b[39mremove_node(node)\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:705\u001b[0m, in \u001b[0;36mSingleThreadedExecutor.spin_once\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspin_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout_sec: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         handler, entity, node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_ready_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ShutdownException:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:691\u001b[0m, in \u001b[0;36mExecutor.wait_for_ready_callbacks\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cb_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_ready_callbacks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cb_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# Generator ran out of work\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cb_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:588\u001b[0m, in \u001b[0;36mExecutor._wait_for_ready_callbacks\u001b[0;34m(self, timeout_sec, nodes, condition)\u001b[0m\n\u001b[1;32m    585\u001b[0m     waitable\u001b[38;5;241m.\u001b[39madd_to_wait_set(wait_set)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# Wait for something to become ready\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m \u001b[43mwait_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_nsec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_shutdown:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ShutdownException()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from tf2_ros.transform_listener import TransformListener\n",
    "from tf2_ros.buffer import Buffer\n",
    "from tf2_ros import TransformException\n",
    "from std_msgs.msg import Float32MultiArray\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.ros_utils import ros_tf_to_matrix\n",
    "\n",
    "\n",
    "\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "node = Node('run_network')\n",
    "    \n",
    "vel_pub = node.create_publisher(Float32MultiArray, '/operational_velocity', 10) \n",
    "tf_buffer = Buffer()\n",
    "tf_listener = TransformListener(tf_buffer, node)\n",
    "\n",
    "\n",
    "def get_transform_ee(base_frame, frame):\n",
    "    msg = None\n",
    "    while msg == None:\n",
    "            rclpy.spin_once(node)\n",
    "            try:\n",
    "                msg = tf_buffer.lookup_transform(base_frame, frame,\n",
    "                                                 rclpy.time.Time())\n",
    "            except TransformException as ex:\n",
    "                pass\n",
    "\n",
    "    return ros_tf_to_matrix(msg)\n",
    "\n",
    "\n",
    "pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "goal = pos.copy()\n",
    "goal[2] += .00\n",
    "goal[1] += 0.1\n",
    "goal[0] += 0.0\n",
    "while np.linalg.norm(pos - goal) > .01:\n",
    "    pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "    xd = np.zeros(6,)\n",
    "    xd[:3] = 1*(goal - pos)\n",
    "    vel_msg = Float32MultiArray()\n",
    "    vel_msg.data = list(xd)\n",
    "    vel_pub.publish(vel_msg)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n",
      "new goal\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "\n",
    "pos_unity = get_transform_ee('unity', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "Tbase_unity = get_transform_ee('base', 'unity')\n",
    "\n",
    "dt = 0.005\n",
    "grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "while True:\n",
    "    pos_unity = get_transform_ee('unity', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "    cur = np.reshape(np.array([pos_unity[0], pos_unity[1], pos_unity[2]]),(1, 1, 1, 1, 3))\n",
    "    query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "    query.unsqueeze(axis=0)\n",
    "    J1, J2 = calculate_gradient(grid_pred, query)\n",
    "    J2 = J2.cpu().detach().numpy()\n",
    "    J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "    J2 = J2.squeeze()\n",
    "#     J2x = J2[0]\n",
    "#     J2z = J2[2]\n",
    "#     J2[0] = J2z\n",
    "#     J2[2] = J2x\n",
    "    \n",
    "    if np.any(np.isnan(J2)):\n",
    "        print(\"nan!\")\n",
    "        J2 = .1*pos_unity/np.linalg.norm(pos_unity)\n",
    "        \n",
    "    goal_unity = pos_unity - J2*dt    \n",
    "    print('new goal')\n",
    "    goal =  (Tbase_unity[:3,:3] @ goal_unity) + Tbase_unity[:3,3]\n",
    "    it = 0\n",
    "    while  it < 10:\n",
    "        pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "        xd = np.zeros(6,)\n",
    "        xd[:3] = 3*(goal - pos)\n",
    "        vel_msg = Float32MultiArray()\n",
    "        vel_msg.data = list(xd)\n",
    "        vel_pub.publish(vel_msg)\n",
    "        it+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c67f5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01530059, 0.00806129, 0.00814947])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41391ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01528889,  0.00805469, -0.00185052])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "733d0516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.22044605e-16,  1.00000000e+00,  0.00000000e+00,\n",
       "         6.58949256e-01],\n",
       "       [-1.00000000e+00,  2.22044605e-16, -0.00000000e+00,\n",
       "        -7.35132322e-02],\n",
       "       [-0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         5.47477603e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tbase_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fc5e6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85801135, -0.04897862,  0.10692175])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82e5fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  3.12250226e-17, -4.16333634e-18,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c81cc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02719753,  0.09231465,  0.0271705 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_unity-pos_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71deb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J1, J2 = calculate_gradient(grid_pred, query)\n",
    "# J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0481d9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 0.27197534, -0.9231464 , -0.27170497]]]]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384dc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nerf",
   "language": "python",
   "name": "thesis_nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
