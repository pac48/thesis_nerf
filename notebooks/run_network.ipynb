{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6de83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from laplacian_py import laplacian_solver\n",
    "\n",
    "resx = 80\n",
    "resy = 30\n",
    "resz = 50\n",
    "\n",
    "resx = 1*64//1\n",
    "resy = 1*64//1\n",
    "resz = 1*64//1\n",
    "\n",
    "max_val = 100/1\n",
    "cost_scale = .000001\n",
    "\n",
    "values = .99*max_val*torch.ones((resx, resy, resz),dtype=torch.float32, device='cuda')\n",
    "cost = cost_scale*torch.ones((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_conditions = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "boundary_types = torch.zeros((resx,resy, resz),dtype=torch.float32, device='cuda')\n",
    "# goal\n",
    "goal_ind1 = int(resx*15/30)\n",
    "goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*27/30)\n",
    "goal_ind3 = int(resz*15/30)\n",
    "boundary_conditions[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "boundary_types[goal_ind1, goal_ind2, goal_ind3] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffe0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m15:52:21 \u001b[0;32mSUCCESS  \u001b[0mInitialized CUDA 12.0. Active GPU is #0: NVIDIA GeForce RTX 4090 [89]\u001b[K\u001b[0m\n",
      "15:52:21 \u001b[0;36mINFO     \u001b[0mLoading network snapshot from: ../nerf/scene.ingp\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.41 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 144 B.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 B.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 1.12 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 4 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 2 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 64 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;36mINFO     \u001b[0mGridEncoding:  Nmin=16 b=2 F=4 T=2^22 L=8\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 0: resolution=16 params_in_level=4096\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 1: resolution=32 params_in_level=32768\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 2: resolution=64 params_in_level=262144\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 3: resolution=128 params_in_level=2097152\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 4: resolution=256 params_in_level=4194304\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 5: resolution=512 params_in_level=4194304\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 6: resolution=1024 params_in_level=4194304\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGridEncoding at level 7: resolution=2048 params_in_level=4194304\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;36mINFO     \u001b[0mDensity model: 3--[HashGrid]-->32--[FullyFusedMLP(neurons=128,layers=4)]-->1\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;36mINFO     \u001b[0mColor model:   3--[Composite]-->16+16--[FullyFusedMLP(neurons=64,layers=4)]-->3\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 2048 params and resetting training.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 8 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 24 KB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;36mINFO     \u001b[0m  total_encoding_params=76693504 total_network_params=29696\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 76723200 params and resetting training.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 293 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 585 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mTrainer: initializing 0 params and resetting training.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 146 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 7 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemory: allocating 4 MB.\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 0 B to 8 MB\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 8 MB to 24 MB\u001b[K\u001b[0m\n",
      "15:52:24 \u001b[0;35mDEBUG    \u001b[0mGPUMemoryArena: enlarging from 24 MB to 40 MB\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts.point_cloud_utils import send_point_cloud\n",
    "from pyngp.common import *\n",
    "from tqdm import tqdm\n",
    "import pyngp.pyngp as ngp\n",
    "testbed = ngp.Testbed()\n",
    "testbed.load_snapshot('../nerf/scene.ingp')\n",
    "\n",
    "box_diff = testbed.aabb.max - testbed.aabb.min\n",
    "min_dim = -box_diff / 2\n",
    "max_dim = box_diff / 2\n",
    "\n",
    "x_segments = np.linspace(.2, .8, resx)\n",
    "y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "z_segments = np.linspace(.35, .65, resz)\n",
    "x, y, z = np.meshgrid(x_segments, y_segments, z_segments, indexing='ij')\n",
    "points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)\n",
    "points = points[0:256 * (points.shape[0] // 256), :]\n",
    "\n",
    "dirs = np.zeros(points.shape)\n",
    "dirs[:, 0] = 1\n",
    "dirs[:, 1] = .5\n",
    "dirs[:, 2] = .5\n",
    "\n",
    "dt = np.zeros((points.shape[0], 1))\n",
    "coords = np.hstack((points, dt, dirs))\n",
    "nerf_values = testbed.sample_nerf(list(coords.flatten()))\n",
    "nerf_values = np.reshape(nerf_values, (coords.shape[0], -1))\n",
    "\n",
    "points = np.vstack((points[:, 0], points[:, 2], 1 - points[:, 1])).T\n",
    "points = points * (max_dim - min_dim) + min_dim\n",
    "points = 2 * points\n",
    "\n",
    "send_point_cloud(np.hstack((points, nerf_values)), has_alpha=False, wait_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7de0bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/CLionProjects/thesis_nerf/venv/lib/python3.10/site-packages/tinycudann-1.7-py3.10-linux-x86_64.egg/tinycudann/modules.py:53: UserWarning: tinycudann was built for lower compute capability (86) than the system's (89). Performance may be suboptimal.\n",
      "  warnings.warn(f\"tinycudann was built for lower compute capability ({cc}) than the system's ({system_compute_capability}). Performance may be suboptimal.\")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from laplacian_py.network import LaplaceNet, compute_loss, calculate_gradient, interpolate_prediction\n",
    "    \n",
    "network = LaplaceNet((resx, resy, resz), max_val, 1*cost_scale, 2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "network = network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07026087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6431.5371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(854.1285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(852.5555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(850.9996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(849.4482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(847.8893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(846.3176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(844.7242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(843.1035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(841.4511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(839.7645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(838.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(836.2764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(834.4736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(832.6288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(830.7411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(828.8098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(826.8366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(824.8231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(822.7678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(820.6727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(818.5362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(816.3621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(814.1525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(811.9054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(809.6238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(807.3076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(804.9593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(802.5776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(800.1722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(797.7411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(795.2861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(792.8049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(790.3033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(787.7887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(785.2612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(782.7227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(780.1806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(777.6384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(775.1024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(772.5745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(770.0614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(767.5760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(765.1201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(762.7045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(760.3348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(758.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(755.7787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(753.6149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(751.5358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(749.5538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(747.6770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(745.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(744.2659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(742.7395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(741.3344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(740.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(738.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(737.8237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(736.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(736.0193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(735.2546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(734.5692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(733.9533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(733.3990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(732.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(732.4421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(732.0247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(731.6400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(731.2828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(730.9487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(730.6339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(730.3350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(730.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(729.7742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(729.5087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(729.2511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(729., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(728.7546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(728.5139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(728.2775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(728.0444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(727.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(727.5871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(727.3624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(727.1403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.7021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.4858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.2715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(726.0588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(725.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(725.6384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(725.4307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(725.2243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(725.0189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(724.8150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(724.6125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(724.4114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(724.2117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(724.0132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(723.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(723.6198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(723.4247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(723.2308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(723.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(722.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(722.6561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(722.4667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(722.2783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(722.0911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.7196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.5352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.3519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(721.1699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.9888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.6292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.4508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.2732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(720.0967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(719.9209, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m pred, C, _ \u001b[38;5;241m=\u001b[39m network(grid_train, boundary_types, boundary_conditions)\n\u001b[0;32m---> 20\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m it \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss_train)\n",
      "File \u001b[0;32m~/CLionProjects/thesis_nerf/nerf_ws/install/laplacian_py/lib/python3.10/site-packages/laplacian_py/network.py:260\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(pred, target, C, cost_scale)\u001b[0m\n\u001b[1;32m    258\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((pred \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m pred\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    259\u001b[0m neg_inds \u001b[38;5;241m=\u001b[39m C \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(neg_inds):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# loss = loss + .00000001 * torch.sum(abs(C[neg_inds]))  # / torch.sum(neg_inds)\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m.01\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mabs\u001b[39m(C[neg_inds]))  \u001b[38;5;66;03m# / torch.sum(neg_inds)\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-4 # norm\n",
    "momentum = 0.8\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "XYZ_train = [np.linspace(-1, 1, res, dtype=np.float32) for res in [resx, resy, resz]]\n",
    "X_train, Y_train, Z_train = np.meshgrid(*XYZ_train)\n",
    "out = np.stack([X_train, Y_train, Z_train], axis=3)\n",
    "grid_train = torch.tensor(out, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "grid_train = grid_train.unsqueeze(axis=0)\n",
    "\n",
    "target = torch.tensor(20*np.sqrt(X_train**2+Y_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(10+20*np.sqrt(X_train**2+Z_train**2),dtype=torch.float32, device='cuda')\n",
    "# target = torch.tensor(21 + 20*Y_train,dtype=torch.float32, device='cuda')\n",
    "\n",
    "    \n",
    "network.reset()\n",
    "for it in range(0, 2000):\n",
    "    optimizer.zero_grad()\n",
    "    pred, C, _ = network(grid_train, boundary_types, boundary_conditions)\n",
    "    loss_train = 1*compute_loss(pred=pred, target=target, C=C, cost_scale=cost_scale)\n",
    "    if it % 10 == 0:\n",
    "        print(loss_train)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "# network = torch.load('network_3d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e802a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "boundary_types_2 = boundary_types.clone()\n",
    "boundary_conditions_2 = boundary_conditions.clone()\n",
    " \n",
    "obj_inds = nerf_values[:,3] > 100/255\n",
    "obj_inds = np.reshape(obj_inds, (resx, resy, resz))\n",
    "obj_inds = torch.tensor(obj_inds) # this should not be needed\n",
    "boundary_conditions_2[obj_inds] = max_val*10\n",
    "boundary_types_2[obj_inds] = 1.0\n",
    "\n",
    "# goal_ind1 = int(resx*15/30)\n",
    "# goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*15/30)\n",
    "# boundary_conditions_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "# boundary_types_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "\n",
    "# goal_ind1 = int(resx*15/30)\n",
    "# goal_ind2 = int(resy*15/30)\n",
    "# goal_ind3 = int(resz*27/30)\n",
    "# boundary_conditions_2[goal_ind1, goal_ind2, goal_ind3] = 0.0\n",
    "# boundary_types_2[goal_ind1, goal_ind2, goal_ind3] = 1.0\n",
    "\n",
    "# network.reset()\n",
    "for i in range(2000):\n",
    "    if i % 100 ==0:\n",
    "        print(i)\n",
    "    pred, C_pos, J2 = network(grid_train, boundary_types_2, boundary_conditions_2)\n",
    "    V_in = pred.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7de01307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from visualization_msgs.msg import MarkerArray, Marker\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "node = Node('visualizer_node')\n",
    "pub = node.create_publisher(MarkerArray, 'visualization_lines', 10)\n",
    "    \n",
    "msg = MarkerArray()\n",
    "\n",
    "dt = 0.001\n",
    "marker_id = 0\n",
    "grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "\n",
    "x_min = points[0,0]\n",
    "y_min = points[0,1]\n",
    "z_min = points[0,2]\n",
    "x_max = points[-1,0]\n",
    "y_max = points[-1,1]\n",
    "z_max = points[-1,2]\n",
    "\n",
    "# x_segments = np.linspace(.2, .8, resx)\n",
    "# y_segments = np.linspace(.45-.02, .59-.02, resy)\n",
    "# z_segments = np.linspace(.35, .65, resz)\n",
    "\n",
    "\n",
    "for z_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "    for y_val in [-.95, -.5, 0, .5 ,.95]:\n",
    "        for x_val in [-.95, 0.0, .95]:\n",
    "            cur = np.reshape(np.array([x_val, y_val, z_val]),(1, 1, 1, 1, 3))\n",
    "            traj = np.zeros((2000, 3))\n",
    "            for i in range(traj.shape[0]):\n",
    "                query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "                query.unsqueeze(axis=0)\n",
    "                J1, J2 = calculate_gradient(grid_pred, query)\n",
    "                J2 = J2.cpu().detach().numpy()\n",
    "#                 J2[abs(J2) != np.max(abs(J2))] = 0\n",
    "                J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "                cur += -J2*dt\n",
    "                traj[i, :] = cur.squeeze()\n",
    "    \n",
    "            marker = Marker()\n",
    "            marker.header.frame_id = \"unity\";\n",
    "            marker.id = marker_id;\n",
    "            marker_id += 1\n",
    "            marker.type = marker.LINE_STRIP;\n",
    "            marker.action = marker.ADD;\n",
    "            \n",
    "            for ind in range(traj.shape[0]):\n",
    "                position = Point()\n",
    "                position.x = .5*(traj[ind, 2]+1.0)*(x_max-x_min) + x_min\n",
    "                position.y = .5*(traj[ind, 1]+1.0)*(y_max-y_min) + y_min\n",
    "                position.z = .5*(traj[ind, 0]+1.0)*(z_max-z_min) + z_min\n",
    "                marker.points.append(position)\n",
    "\n",
    "            marker.scale.x = .0025;\n",
    "            marker.scale.y = 0.0;\n",
    "            marker.scale.z = 0.0;\n",
    "            marker.color.a = 1.0; \n",
    "            marker.color.r = 0.0;\n",
    "            marker.color.g = 0.0;\n",
    "            marker.color.b = 1.0;\n",
    "\n",
    "            msg.markers.append(marker)\n",
    "\n",
    "\n",
    "pub.publish(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42f5f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pub.publish(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51666b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1699043028.806189614] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n"
     ]
    }
   ],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from tf2_ros.transform_listener import TransformListener\n",
    "from tf2_ros.buffer import Buffer\n",
    "from tf2_ros import TransformException\n",
    "from std_msgs.msg import Float32MultiArray\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.ros_utils import ros_tf_to_matrix\n",
    "\n",
    "\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "node = Node('run_network')\n",
    "    \n",
    "vel_pub = node.create_publisher(Float32MultiArray, '/operational_velocity', 10) \n",
    "tf_buffer = Buffer()\n",
    "tf_listener = TransformListener(tf_buffer, node)\n",
    "\n",
    "\n",
    "def get_transform_ee(base_frame, frame):\n",
    "    msg = None\n",
    "    while msg == None:\n",
    "            rclpy.spin_once(node)\n",
    "            try:\n",
    "                msg = tf_buffer.lookup_transform(base_frame, frame,\n",
    "                                                 rclpy.time.Time())\n",
    "            except TransformException as ex:\n",
    "                pass\n",
    "\n",
    "    return ros_tf_to_matrix(msg)\n",
    "\n",
    "\n",
    "def publish_traj(traj, pub):\n",
    "    msg = MarkerArray()\n",
    "    marker = Marker()\n",
    "    marker.header.frame_id = \"unity\"\n",
    "    marker.id = 99999\n",
    "    marker.type = marker.LINE_STRIP\n",
    "    marker.action = marker.ADD\n",
    "\n",
    "    for ind in range(traj.shape[0]):\n",
    "        position = Point()\n",
    "        position.x = .5*(traj[ind, 2]+1.0)*(x_max-x_min) + x_min\n",
    "        position.y = .5*(traj[ind, 1]+1.0)*(y_max-y_min) + y_min\n",
    "        position.z = .5*(traj[ind, 0]+1.0)*(z_max-z_min) + z_min\n",
    "        marker.points.append(position)\n",
    "\n",
    "    marker.scale.x = .0025;\n",
    "    marker.scale.y = 0.0;\n",
    "    marker.scale.z = 0.0;\n",
    "    marker.color.a = 1.0; \n",
    "    marker.color.r = 1.0;\n",
    "    marker.color.g = 0.0;\n",
    "    marker.color.b = 0.0;\n",
    "\n",
    "    msg.markers.append(marker)\n",
    "\n",
    "    for i in range(100):\n",
    "        pub.publish(msg)\n",
    "\n",
    "    \n",
    "pos_unity = get_transform_ee('unity', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "pos_network = np.array([pos_unity[0], pos_unity[1], pos_unity[2]])\n",
    "pos_network[0] = (pos_network[0]-x_min)/(.5*(x_max-x_min))\n",
    "pos_network[1] = (pos_network[1]-y_min)/(.5*(y_max-y_min))\n",
    "pos_network[2] = (pos_network[2]-z_min)/(.5*(z_max-z_min))\n",
    "pos_network = pos_network-1.0\n",
    "pos_network = np.array([pos_network[2], pos_network[1], pos_network[0]])\n",
    "\n",
    "\n",
    "cur = np.reshape(pos_network.copy(), (1, 1, 1, 1, 3))\n",
    "traj = np.zeros((2000, 3))\n",
    "dt = 0.001\n",
    "for i in range(traj.shape[0]):\n",
    "    query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "    query.unsqueeze(axis=0)\n",
    "    J1, J2 = calculate_gradient(grid_pred, query)\n",
    "    J2 = J2.cpu().detach().numpy()\n",
    "#     if np.linalg.norm(J2) < 0.001:\n",
    "#         J2 = np.random.rand(*J2.shape)\n",
    "    J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "    cur += -J2*dt\n",
    "    traj[i, :] = cur.squeeze()\n",
    "\n",
    "\n",
    "publish_traj(traj, pub)\n",
    "\n",
    "pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "\n",
    "\n",
    "# goal = pos.copy()\n",
    "# goal[2] += .00\n",
    "# goal[1] += 0.1\n",
    "# goal[0] += 0.0\n",
    "# while np.linalg.norm(pos - goal) > .01:\n",
    "#     pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "#     xd = np.zeros(6,)\n",
    "#     xd[:3] = 1*(goal - pos)\n",
    "#     vel_msg = Float32MultiArray()\n",
    "#     vel_msg.data = list(xd)\n",
    "#     vel_pub.publish(vel_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12ba3127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08004006, -0.65846928, -0.83279764])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44a29955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rclpy\n",
    "# from rclpy.node import Node\n",
    "# from tf2_ros.transform_listener import TransformListener\n",
    "# from tf2_ros.buffer import Buffer\n",
    "# from tf2_ros import TransformException\n",
    "# from std_msgs.msg import Float32MultiArray\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "# from scripts.ros_utils import ros_tf_to_matrix\n",
    "\n",
    "\n",
    "\n",
    "# if not rclpy.ok():\n",
    "#     rclpy.init()\n",
    "# node = Node('run_network')\n",
    "    \n",
    "# vel_pub = node.create_publisher(Float32MultiArray, '/operational_velocity', 10) \n",
    "# tf_buffer = Buffer()\n",
    "# tf_listener = TransformListener(tf_buffer, node)\n",
    "\n",
    "\n",
    "# def get_transform_ee(base_frame, frame):\n",
    "#     msg = None\n",
    "#     while msg == None:\n",
    "#             rclpy.spin_once(node)\n",
    "#             try:\n",
    "#                 msg = tf_buffer.lookup_transform(base_frame, frame,\n",
    "#                                                  rclpy.time.Time())\n",
    "#             except TransformException as ex:\n",
    "#                 pass\n",
    "\n",
    "#     return ros_tf_to_matrix(msg)\n",
    "\n",
    "\n",
    "pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "goal = pos.copy()\n",
    "goal[2] += -.00\n",
    "goal[1] += 0.0\n",
    "goal[0] += 0.0\n",
    "while np.linalg.norm(pos - goal) > .01:\n",
    "    pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "    xd = np.zeros(6,)\n",
    "    xd[:3] = 1*(goal - pos)\n",
    "    vel_msg = Float32MultiArray()\n",
    "    vel_msg.data = list(xd)\n",
    "    vel_pub.publish(vel_msg)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "# pos_unity = get_transform_ee('unity', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "# Tbase_unity = get_transform_ee('base', 'unity')\n",
    "\n",
    "# dt = 0.005\n",
    "# grid_pred = pred[1:-1, 1:-1, 1:-1].unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "# while True:\n",
    "#     pos_unity = get_transform_ee('unity', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "#     cur = np.reshape(np.array([pos_unity[0], pos_unity[1], pos_unity[2]]),(1, 1, 1, 1, 3))\n",
    "#     query = torch.tensor(cur, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "#     query.unsqueeze(axis=0)\n",
    "#     J1, J2 = calculate_gradient(grid_pred, query)\n",
    "#     J2 = J2.cpu().detach().numpy()\n",
    "#     J2 = J2/(np.linalg.norm(J2) + .001)\n",
    "#     J2 = J2.squeeze()\n",
    "# #     J2x = J2[0]\n",
    "# #     J2z = J2[2]\n",
    "# #     J2[0] = J2z\n",
    "# #     J2[2] = J2x\n",
    "    \n",
    "#     if np.any(np.isnan(J2)):\n",
    "#         print(\"nan!\")\n",
    "#         J2 = .1*pos_unity/np.linalg.norm(pos_unity)\n",
    "        \n",
    "#     goal_unity = pos_unity - J2*dt    \n",
    "#     print('new goal')\n",
    "#     goal =  (Tbase_unity[:3,:3] @ goal_unity) + Tbase_unity[:3,3]\n",
    "#     it = 0\n",
    "#     while  it < 10:\n",
    "#         pos = get_transform_ee('base', 'right_gripper_l_finger_tip')[:3, 3]\n",
    "#         xd = np.zeros(6,)\n",
    "#         xd[:3] = 3*(goal - pos)\n",
    "#         vel_msg = Float32MultiArray()\n",
    "#         vel_msg.data = list(xd)\n",
    "#         vel_pub.publish(vel_msg)\n",
    "#         it+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67f5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41391ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tbase_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81cc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_unity-pos_unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71deb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J1, J2 = calculate_gradient(grid_pred, query)\n",
    "# J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384dc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nerf",
   "language": "python",
   "name": "thesis_nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
